llm:
  model: "gpt-4.1-mini"
  base_url: "${OPENAI_BASE_URL:-https://api.openai.com/v1}"
  api_key: "${OPENAI_API_KEY}"
  temperature: 1.0
  max_tokens: 1024

params:
  index: "msmarco-v1-passage"
  retrieval_k: 10
  k1: 0.9
  b: 0.4
  rm3: false
  rocchio: false
  rocchio_use_negative: false
  disable_bm25_param: true
  batch_size: 128
  threads: 16
  parallel: false  # Enable parallel generation for methods like MuGI

# Method-specific default parameters
genqr:
  llm:
    temperature: 0.7
    max_tokens: 256
  params:
    n_generations: 5  # Number of times to call LLM for keywords

query2e:
  llm:
    temperature: 0.7  
    max_tokens: 256
  params:
    mode: "zs"  # "zs" (zero-shot) or "fs" (few-shot with dynamic examples)
    num_examples: 4  # Number of few-shot examples (only used when mode="fs")
    max_keywords: 20  # Maximum number of keywords to generate
    # Few-shot data loading (only needed for mode="fs"):
    # dataset_type: "msmarco"  # "msmarco", "beir", or "generic"
    # For MS MARCO:
    #   collection_path: "path/to/collection.tsv"
    #   train_queries_path: "path/to/queries.tsv"
    #   train_qrels_path: "path/to/qrels.txt"
    # For BEIR:
    #   beir_data_dir: "path/to/beir/dataset"
    #   train_split: "train"  # or "dev"
    # For generic:
    #   collection_path: "path/to/collection.tsv"  # TSV: docid \t text
    #   train_queries_path: "path/to/queries.tsv"  # TSV: qid \t query
    #   train_qrels_path: "path/to/qrels.txt"  # TREC format

query2doc:
  llm:
    temperature: 0.7
    max_tokens: 256
  params:
    mode: "zs"  # "zs" (zero-shot), "cot" (chain-of-thought), or "fs" (few-shot)
    num_examples: 4  # Number of few-shot examples (only used when mode="fs")
    # Few-shot data loading (only needed for mode="fs"):
    # dataset_type: "msmarco"  # "msmarco", "beir", or "generic"
    # For MS MARCO:
    #   collection_path: "path/to/collection.tsv"
    #   train_queries_path: "path/to/queries.tsv"
    #   train_qrels_path: "path/to/qrels.txt"
    # For BEIR:
    #   beir_data_dir: "path/to/beir/dataset"
    #   train_split: "train"  # or "dev"
    # For generic:
    #   collection_path: "path/to/collection.tsv"  # TSV: docid \t text
    #   train_queries_path: "path/to/queries.tsv"  # TSV: qid \t query
    #   train_qrels_path: "path/to/qrels.txt"  # TREC format

qa_expand:
  llm:
    temperature: 0.8
    max_tokens: 256
  params:
    temperature_subq: 0.7  # Temperature for sub-question generation
    temperature_answer: 0.7  # Temperature for answer generation
    temperature_refine: 0.7  # Temperature for answer refinement
    prompt_subq: "qa_expand.subq.v1"  # Prompt ID for sub-question generation
    prompt_answer: "qa_expand.answer.v1"  # Prompt ID for answer generation
    prompt_refine: "qa_expand.refine.v1"  # Prompt ID for answer refinement

genqr_ensemble:
  llm:
    temperature: 0.92  # Nucleus sampling (GenQREnsemble paper)
    max_tokens: 256
  params:
    parallel: false  # Sequential generation by default (set true for parallel)

mugi:
  llm:
    temperature: 1.0  # High temperature for diversity (MuGI paper)
    max_tokens: 1024  # Max tokens per pseudo-document generation
  params:
    num_docs: 5  # Number of pseudo-documents to generate (doc_gen in paper)
    adaptive_times: 6  # Adaptive repetition divisor (default from paper)
    parallel: false  # Sequential generation by default (set true for parallel)
    mode: "zs"  # "zs" (zero-shot) or "fs" (few-shot)

seed: 17
retries: 2
